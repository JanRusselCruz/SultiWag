# SultiWag: Indigenous Language Classification and Word-to-Word Translation using Artificial Neural Networks

It has been a terrible healthcare quality for indigenous communities, as they faced several difficulties from receiving even the most basic services of modern technology, notably in healthcare. They are confronted with multiple challenges in accessing quality healthcare, such as: shortage of health facilities in their indigenous communities, absence of health insurance or the lacking the economic capability to pay for healthcare services, cultural differences with the healthcare professionals such as difference in languages and illiteracy, complex healthcare procedures in health establishments, and healthcare professionals’ little to no understanding of indigenous culture. Indigenous people and non-indigenous healthcare professionals communicating proved to be difficult. Yet, communication is one of the most important factors in patient-relationship healthcare. Both indigenous people and non-indigenous healthcare professionals struggle to provide and receive proper quality healthcare because of the language barrier. The researchers of this study built SultiWag, a mobile application that can classify spoken indigenous language used in an audio clip and translate it into English. SultiWag classifies four language categories: Manobo, Kagan, and Davaoeño-Cebuano. SultiWag aims to improve communications between indigenous people in relation with their access to healthcare, and non-indigenous health professionals, as well as preserve an ancient indigenous language that is on the verge of extinction. The researchers of this study in collaboration with the Kaag research study led by Mrs. Shenna Cloribel and the Lumon Community have traveled to the locations where both of the indigenous tribes reside. The researchers were able build a dataset spreadsheet of translations from the data gathered from the Indigenous tribes of Boston-Simulao-Manobo and Banaybanay-Kagan in Davao-Oriental with the permission, guidance, and assistance of the National Commission on Indigenous Peoples (NCIP) throughout the data gathering expedition along with the raw audio extracted from the recording sessions. The raw audio was pre-processed by cutted into audio clips, extracted as mp3, and then converted into spectrograms. Every mp3 was then linked to the appropriate word in the dataset spreadsheet. The produced data from pre-processing had an overall total of four-thousand two-hundred ninty-seven (4,297) from the three (3) language, along with an overall total of three-hundred eighty-four (384) health term. Proceeding to the preparation of data. The researchers built two types of data: inconsistent data and consistent data. The inconsistent data had a total of ten-thousand eight-hundred thirteen (10,813) and a consistent data of seventeen-thousand five-hundred twenty(17,520). The researchers then constructed eight (8) CNN models, five (5) were classification models and three (3) were transcription models. The classification model was fed with both types of data while the transcription model was fed only the consistent data. The highest performing model for classification had a val_accuracy of 0.69 and a val_loss of 3.95 for inconsistent data and a val_accuracy of 0.75 and a val_loss of 2.72 for consistent data. Along with the highest performing transcription model with a val_accuracy of 0.04 and a val_loss of 9.20. The final result being, the classification model had a 75% chance of predicting the correct language. While the transcription model has an 8% chance of predicting and transcribing the correct word based only on the data available.
