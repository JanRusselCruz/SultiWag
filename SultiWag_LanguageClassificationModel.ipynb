{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanRusselCruz/SultiWag/blob/Source_Code/SultiWag_LanguageClassificationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "zN4MbKGX-DOG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q20eXlByLM1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg49NCscvf3K"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "import os\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow\n",
        "from PIL import Image, ImageChops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pppNEgUFyTu4"
      },
      "outputs": [],
      "source": [
        "path = \"/content/gdrive/MyDrive/SultiWag/AudioFiles/02_Spectrograms/Consistent584_Spectrograms\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions and  Models\n"
      ],
      "metadata": {
        "id": "gLRdST6z-PrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_numpy_from_spectrograms(path = \"\"):\n",
        "    numpy_array = []    \n",
        "    for filename in tqdm(glob.glob(os.path.join(path, '*.jpg'))):\n",
        "        img = Image.open(filename)\n",
        "        img = trim(img)\n",
        "        h, w = img.size\n",
        "        tmp_img = np.array(img)        \n",
        "        np_img = []\n",
        "        np_img = tmp_img[round(h/2)-1:h-1]\n",
        "        file = filename.split(\"/\")[-1].split(\".\")[0]\n",
        "        term = file.split(\"_\")  \n",
        "        english = term[0]  \n",
        "        translation = term[1]  \n",
        "        if len(term) < 3:\n",
        "            translation_language = \"\" \n",
        "        else:\n",
        "            translation_language = term[2].split(\"(\")[-1].split(\")\")[0]  \n",
        "            translation = term[1].replace(term[2], \"\")  \n",
        "            translation = f\"{translation}({translation_language})\"  \n",
        "        translation_language='cebuano'\n",
        "        if('(M' in translation):\n",
        "            translation_language='manobo'\n",
        "        elif('(K' in translation):\n",
        "            translation_language='kagan'\n",
        "        np_img_flipped = np.fliplr(np_img)  \n",
        "        numpy_array.append([english, translation, translation_language, np_img/255])\n",
        "        numpy_array.append([english, translation, translation_language, np_img_flipped/255])\n",
        "    \n",
        "    numpy_array.sort(key=lambda x: x[2]) \n",
        "    alternating_array = []\n",
        "    manobo_array = []\n",
        "    kagan_array = []\n",
        "    cebuano_array = []\n",
        "    for item in numpy_array:\n",
        "        if item[2] == 'manobo':\n",
        "            manobo_array.append(item)\n",
        "        elif item[2] == 'kagan':\n",
        "            kagan_array.append(item)\n",
        "        else:\n",
        "            cebuano_array.append(item)\n",
        "    max_len = max(len(manobo_array), len(kagan_array), len(cebuano_array))\n",
        "    for i in range(max_len):\n",
        "        if i < len(manobo_array):\n",
        "            alternating_array.append(manobo_array[i])\n",
        "        if i < len(kagan_array):\n",
        "            alternating_array.append(kagan_array[i])\n",
        "        if i < len(cebuano_array):\n",
        "            alternating_array.append(cebuano_array[i])\n",
        "    \n",
        "    np.save(\"data.npy\", alternating_array)\n",
        "    return alternating_array"
      ],
      "metadata": {
        "id": "Io2nB0Na8wI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxGuQ4VryfkT"
      },
      "outputs": [],
      "source": [
        "# function to load the numpy array\n",
        "\n",
        "def load_data(filename=\"\"):\n",
        "    spectrograms = []    \n",
        "    \n",
        "    data = np.load(\"data.npy\", allow_pickle=True)\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqrLyD7xyh7A"
      },
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "    model = Sequential()    \n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(51, 336, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv1D(24, 10, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv1D(12, 10, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Conv1D(5, 11, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\t# compile model\n",
        "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtUZuvHd7IS0"
      },
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model2():\n",
        "    model = Sequential()    \n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(51, 336, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv1D(24, 10, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv1D(12, 10, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Conv1D(5, 11, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\t# compile model\n",
        "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7Bf9S-JGG5E"
      },
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model3():\n",
        "    model = Sequential()    \n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(51, 336, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv1D(24, 10, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv1D(12, 10, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Conv1D(5, 11, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\t# compile model\n",
        "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsI3Nd-APxA6"
      },
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model4():\n",
        "    model = Sequential()    \n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(51, 336, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv1D(24, 10, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Conv1D(12, 10, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Conv1D(5, 11, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1000, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\t# compile model\n",
        "    opt = SGD(learning_rate=0.05, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def define_model5():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(51, 336, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    \n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "bOA5fTR_5e42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwyRkfZuyjZQ"
      },
      "outputs": [],
      "source": [
        "def trim(im):\n",
        "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
        "    diff = ImageChops.difference(im, bg)\n",
        "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        return im.crop(bbox)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Other codes"
      ],
      "metadata": {
        "id": "WtlWq1g__DQH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWuTISh4yl9W"
      },
      "outputs": [],
      "source": [
        "data = create_numpy_from_spectrograms(path) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI8G9TqLyoIl"
      },
      "outputs": [],
      "source": [
        "np.save('data.npy',data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWk_t5Vgyp5z"
      },
      "outputs": [],
      "source": [
        "data = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GObHFVB6ywbH"
      },
      "outputs": [],
      "source": [
        "X = np.array([row[3] for row in data])\n",
        "Y_english = np.array([row[0] for row in data])\n",
        "Y_translation = np.array([row[1] for row in data])\n",
        "Y_language = np.array([row[2] for row in data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP86DiOXyxvV",
        "outputId": "af547f45-6dbc-43ab-be8d-f5879181b60d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8760\n",
            "8760\n"
          ]
        }
      ],
      "source": [
        "if len(X) < len(Y_language):\n",
        "    Y_language = Y_language[:len(X)]\n",
        "else:\n",
        "    X = X[:len(Y_language)]\n",
        "\n",
        "print(len(X))\n",
        "print(len(Y_language))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QMETjacy2gD"
      },
      "outputs": [],
      "source": [
        "np.save('X.npy',X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUm4A-z5y4I6"
      },
      "outputs": [],
      "source": [
        "np.save('Y_english.npy',Y_english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXPPZJx1y52A"
      },
      "outputs": [],
      "source": [
        "np.save('Y_translation.npy',Y_translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO64c6awy7M9"
      },
      "outputs": [],
      "source": [
        "np.save('Y_language.npy',Y_language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ea7ivPTy8mt"
      },
      "outputs": [],
      "source": [
        "Y_language_label = LabelEncoder()\n",
        "Y_language_vec = Y_language_label.fit_transform(Y_language)\n",
        "Y_language_vec = to_categorical(Y_language_vec, dtype =\"uint8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVLhrPRky-Pj"
      },
      "outputs": [],
      "source": [
        "np.save('Y_language_label', Y_language_label)\n",
        "np.save('Y_language_vec', Y_language_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4uB5GpxzAAF"
      },
      "outputs": [],
      "source": [
        "classes = list(np.unique(Y_language))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWzRMxfxzBZ_"
      },
      "outputs": [],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6pCv_VEzCn7"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    rand = Y_language[i]\n",
        "    print(rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAaY5EkwzEGD"
      },
      "outputs": [],
      "source": [
        "np.savetxt(\"y_language.txt\",Y_language,fmt='%s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKfKCKNUzFmr"
      },
      "outputs": [],
      "source": [
        "Y = []\n",
        "for y in Y_language:\n",
        "  Y.append(classes.index(y))\n",
        "\n",
        "Y=np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lshh7CnzG_d"
      },
      "outputs": [],
      "source": [
        "np.save('Y.npy',Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start Training"
      ],
      "metadata": {
        "id": "LqPso6jb_Ixv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Je0Wydx9zIZy"
      },
      "outputs": [],
      "source": [
        "x_len = len(X)\n",
        "y_len = len(Y_language)\n",
        "\n",
        "#get 70% of the data\n",
        "train_end = round(.7*(x_len))\n",
        "train_X = X[:train_end]\n",
        "train_Y = Y[:train_end]\n",
        "\n",
        "\n",
        "test_start = train_end\n",
        "test_X = X[test_start:x_len]\n",
        "test_Y = Y[test_start:y_len]\n",
        "\n",
        "train_X = train_X.reshape((train_X.shape[0], 51, 336, 3))\n",
        "test_X = test_X.reshape((test_X.shape[0], 51, 336, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZJYyaW--qXE"
      },
      "outputs": [],
      "source": [
        "# Create the Validation Dataset\n",
        "Xtrain, Xval, ytrain, yval = train_test_split(X, Y,  test_size=0.1, random_state=42)# Create the Test and Final Training Datasets\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(Xtrain, ytrain, train_size=0.70, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uHBaKunFl4_"
      },
      "outputs": [],
      "source": [
        "print(x_len,y_len)\n",
        "print(len(train_X))\n",
        "print(len(test_X))\n",
        "print(len(Xtrain),len(Xtest),len(Xval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ojVe6Zl-kAP"
      },
      "outputs": [],
      "source": [
        "print(len(test_X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXvwrNFazLdE"
      },
      "outputs": [],
      "source": [
        "# train_X = train_X.reshape((train_X.shape[0], 216, 288, 3))\n",
        "# test_X = test_X.reshape((test_X.shape[0], 216, 288, 3))\n",
        "train_X = train_X.reshape((train_X.shape[0], 51, 336, 3))\n",
        "test_X = test_X.reshape((test_X.shape[0], 51, 336, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdhZ7HEjzM2m"
      },
      "outputs": [],
      "source": [
        "print(Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl_kRgJPzO5T"
      },
      "outputs": [],
      "source": [
        "train_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTDbwu5_zRJM"
      },
      "outputs": [],
      "source": [
        "model = define_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FnBdNs18C3O"
      },
      "outputs": [],
      "source": [
        "model2 = define_model2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl2IWdYoGNBs"
      },
      "outputs": [],
      "source": [
        "model3 = define_model3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_M35za7P8gk"
      },
      "outputs": [],
      "source": [
        "model4 = define_model4()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = define_model5()"
      ],
      "metadata": {
        "id": "5Vl4WuZcJZym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4i4INmKzSx0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits= False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(Xtrain, ytrain, epochs=100, validation_data=(Xtest, ytest))        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2ijD5W98FnS"
      },
      "outputs": [],
      "source": [
        "model2.compile(optimizer='adam',\n",
        "              loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits= False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# history2 = model2.fit(train_X, train_Y, epochs=100, validation_data=(test_X, test_Y))        \n",
        "history2 = model2.fit(Xtrain, ytrain, epochs=300, validation_data=(Xtest,ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAgzRLlLGRT9"
      },
      "outputs": [],
      "source": [
        "model3.compile(optimizer='adam',\n",
        "              loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history3 = model3.fit(Xtrain, ytrain, epochs=500, validation_data=(Xtest,ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlCY2KrvQAd9"
      },
      "outputs": [],
      "source": [
        "model4.compile(optimizer='adam',\n",
        "              loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history4 = model4.fit(Xtrain, ytrain, epochs=500, validation_data=(Xtest,ytest))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(optimizer='adam',\n",
        "              loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history5 = model5.fit(Xtrain, ytrain, epochs=500, validation_data=(Xtest,ytest))"
      ],
      "metadata": {
        "id": "COSiK3_EJzoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotting of the Graph"
      ],
      "metadata": {
        "id": "9id5afBk_cIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umhlfUtYzU1b"
      },
      "outputs": [],
      "source": [
        "def plot_model(history):\n",
        "  plt.plot(history.history['accuracy'], label='accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim([0.0, 1])\n",
        "  plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3uPTeQz9DSc"
      },
      "outputs": [],
      "source": [
        "plot_model(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHTY-VmUPNyi"
      },
      "outputs": [],
      "source": [
        "plot_model(history2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsbWtfmGPQx7"
      },
      "outputs": [],
      "source": [
        "plot_model(history3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(history5)"
      ],
      "metadata": {
        "id": "qvHZwmVPGT02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89xnpzKOzWdN"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model5.evaluate(Xtest,  ytest, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR6h92gBzX7W"
      },
      "outputs": [],
      "source": [
        "prediction  = model5.predict(Xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yITPxwOzZat"
      },
      "outputs": [],
      "source": [
        "prediction  = model5.predict(Xtrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBVbj6-Iza9k"
      },
      "outputs": [],
      "source": [
        "prediction_labels = []\n",
        "for p in prediction:\n",
        "  c = round(max(p))\n",
        "  prediction_labels = classes[c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u50i3XD-zcQG"
      },
      "outputs": [],
      "source": [
        "classes_x=np.argmax(prediction,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHtlVmJ5zdt9"
      },
      "outputs": [],
      "source": [
        "classes_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF9OibSwzfAU"
      },
      "outputs": [],
      "source": [
        "model.save('Classification_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHnsEzUg7m5W"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the trained model\n",
        "model = define_model5()  # Define the model here\n",
        "\n",
        "# Load the test data\n",
        "Xtrain, Xval, ytrain, yval = train_test_split(X, Y,  test_size=0.1, random_state=42)\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(Xtrain, ytrain, train_size=0.70, random_state=42)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(Xtest)\n",
        "\n",
        "classes_x = np.argmax(y_pred, axis=1)  # Use y_pred to calculate the class labels\n",
        "\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(ytest, classes_x)\n",
        "precision = precision_score(ytest, classes_x, average='weighted')\n",
        "recall = recall_score(ytest, classes_x, average='weighted')\n",
        "f1 = f1_score(ytest, classes_x, average='weighted')\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
        "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "print(\"F1-Score: {:.2f}%\".format(f1 * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MciQt6M4AJtZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model2 = load_model('Classification_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tYUTF8_BQ-B"
      },
      "outputs": [],
      "source": [
        "def load_recording_spectrograph(file=''):\n",
        "    y, sr = librosa.load(file, sr=44100)\n",
        "    f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
        "    times = librosa.times_like(f0)\n",
        "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "    fig, ax = plt.subplots()\n",
        "    img = librosa.display.specshow(D)  \n",
        "    fig.savefig(file+\".jpg\")\n",
        "    img2 = Image.open(file+\".jpg\")  \n",
        "    return img2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfY8BQfxHBDj"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/gdrive/MyDrive/SultiWag/AudioFiles/01_SlicedAudio/Cebuano/Cebuano_All_Letters\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGCjSxvSGncK"
      },
      "outputs": [],
      "source": [
        "chest = load_recording_spectrograph(data_path+\"/haughty_hambog(C).mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYZ5-fQrHzKS"
      },
      "outputs": [],
      "source": [
        "def trim(im):\n",
        "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
        "    diff = ImageChops.difference(im, bg)\n",
        "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        return im.crop(bbox)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGd_Kej9H1gb"
      },
      "outputs": [],
      "source": [
        "img=trim(chest)\n",
        "h, w = img.size\n",
        "tmp_img = np.array(img)\n",
        "np_img = []\n",
        "np_img = tmp_img[round(h/2)-1:h-1]   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BMJFJFKH3iC"
      },
      "outputs": [],
      "source": [
        "np_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cAgiRhWH_PS"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkMRpRhGH_mt"
      },
      "outputs": [],
      "source": [
        "# shape when training/testing = [batch size, img_height, img_width, img_channels]\n",
        "test_X1 = np_img\n",
        "test_X1 = np.expand_dims(test_X1, axis=0)\n",
        "print(test_X1.shape)\n",
        "prediction  = model2.predict(test_X1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V5Iw1UoICsl"
      },
      "outputs": [],
      "source": [
        "classes_x=np.argmax(prediction,axis=1)\n",
        "classes_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhzH2FXZIE9S"
      },
      "outputs": [],
      "source": [
        "if classes_x[0] == 1:\n",
        "  print(\"Kagan\")\n",
        "elif classes_x[0] == 0:\n",
        "  print(\"Cebuano\")\n",
        "elif classes_x[0] == 2:\n",
        "  print(\"Manobo\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}